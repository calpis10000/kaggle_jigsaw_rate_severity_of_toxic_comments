{"cells":[{"cell_type":"markdown","metadata":{"id":"91pntadwaltE"},"source":["\n","\n","# Jigsaw Rate Severity of Toxic Comments"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1644160037095,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"afLlXS5HxnGq","outputId":"a704a6b3-84b8-4d80-88b0-e4cbdab90f27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Feb  6 15:07:16 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18551,"status":"ok","timestamp":1644160055641,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"FxOWaIAm0bdv","outputId":"02fc55f7-9a48-4e7d-a364-c710f6056250"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 3.5 MB 15.7 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 68.2 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 53.6 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 63.8 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 13.3 MB/s \n","\u001b[?25h"]}],"source":["# install librariess\n","!pip install transformers -q\n","!pip install sentencepiece -q"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9720,"status":"ok","timestamp":1644160065356,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"FC38hq161dFn"},"outputs":[],"source":["# ----------------------------------------------\n","# Load Libraries\n","# ----------------------------------------------\n","import pathlib\n","from pathlib import Path\n","import sys\n","import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import BertForSequenceClassification, BertConfig, BertModel\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","import gc\n","gc.enable()"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":970,"status":"ok","timestamp":1644192371672,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"apbpcmylulBP"},"outputs":[],"source":["# ----------------------------------------------\n","# Config\n","# ----------------------------------------------\n","COLAB = True\n","DEBUG = False\n","TRAIN = True\n","RUN_VALID = True\n","\n","USERID = 'calpis10000'\n","EX_NO = 'jigsaw-calpis-012'\n","UPLOAD_DIR = Path('/content/model')\n","UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\n","\n","COLAB_BASE_DIR = Path(f\"../\")\n","OUT_DIR = COLAB_BASE_DIR/f\"output/{EX_NO}\"\n","COLAB_INPUT_DIR = COLAB_BASE_DIR/\"input\"\n","\n","INPUT_BASE = Path('./') if COLAB else Path('../')\n","INPUT_DIR_0 = INPUT_BASE/'input/jigsaw-toxic-severity-rating/'\n","INPUT_DIR_1 = INPUT_BASE/'input/PuseudoLabelingJigsaw/jigsaw-toxic-comment-classification-challenge/'\n","INPUT_DIR_2 = INPUT_BASE/'input/PuseudoLabelingJigsaw/jigsaw-unintended-bias-in-toxicity-classification/'\n","INPUT_DIR_R = INPUT_BASE/'input/PuseudoLabelingJigsaw/ruddit-dataset/'\n","\n","FOLDS = 5\n","NUM_CLASSES = 1\n","NUM_EPOCHS = 6\n","BATCH_SIZE = 32\n","BATCH_SIZE_PRED = 512\n","MAX_LEN = 128\n","LEANING_RATE = 2e-5\n","LOG_INTERVAL = 100\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cudaがなければcpuを使えばいいじゃない\n","PRETRAINED = 'unitary/multilingual-toxic-xlm-roberta'\n","TOKENIZER = PRETRAINED\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1644192786962,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"VRCYMajl0r1E"},"outputs":[],"source":["if COLAB:\n","  OUT_DIR.mkdir(parents=True, exist_ok=True)\n","  !cp -r -f {str(COLAB_INPUT_DIR)}/ \".\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1378,"status":"ok","timestamp":1644160173455,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"ZtARtCuEwFVx","outputId":"ecdf1c75-7ad4-4515-90ad-18adb182f92c"},"outputs":[{"name":"stdout","output_type":"stream","text":["load data: this competition\n","load data: twitter\n"]}],"source":["# ----------------------------------------------\n","# Load Data\n","# ----------------------------------------------\n","# INPUT_0: This Competition\n","submission = pd.read_csv(INPUT_DIR_0/'sample_submission.csv')\n","val_data = pd.read_csv(INPUT_DIR_0/'validation_data.csv')\n","test = pd.read_csv(INPUT_DIR_0/'comments_to_score.csv')\n","print('load data: this competition')\n","\n","# INPUT_1: 1st Competition\n","#train_1st = pd.read_csv(INPUT_DIR_1/'train.csv')\n","#test_1st = pd.read_csv(INPUT_DIR_1/'test.csv')\n","#test_labels_1st = pd.read_csv(INPUT_DIR_1/'test_labels.csv')\n","#print('load data: 1st competition')\n","\n","# INPUT_2: 2nd Competition\n","#train_2nd = pd.read_csv(INPUT_DIR_2/'train.csv')\n","#test_2nd = pd.read_csv(INPUT_DIR_2/'test.csv')\n","#idt_indiv_anno = pd.read_csv(INPUT_DIR_2/'identity_individual_annotations.csv')\n","#tox_indiv_anno = pd.read_csv(INPUT_DIR_2/'toxicity_individual_annotations.csv')\n","#print('load data: 2nd competition')\n","\n","# INPUT_R: Ruddit Competition\n","#ruddit = pd.read_csv('/content/input/PuseudoLabelingJigsaw/rudddit-dataset/PseudoLabelDataset (1).csv')\n","#print('load data: ruddit competition')\n","\n","# twitter_pseudo_label\n","twitter = pd.read_csv(INPUT_BASE'/input/PuseudoLabelingJigsaw/toxic-twitter-dataset/PseudoLabelDataset (2).csv')\n","print('load data: twitter')\n","\n","# 1st_pseudo_label\n","#train_1st_pseudo = pd.read_csv('/content/input/PuseudoLabelingJigsaw/jigsaw-toxic-comment-classification-challenge/PseudoLabelDataset.csv')\n","#print('load data: 1st_pseudo_label')\n","\n","\n","# ----------------------------------------------\n","# Set SEED\n","# ----------------------------------------------\n","# seed\n","SEED = 2021\n","def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    \n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    \n","set_seed(SEED)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1644160173455,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"M9CakFuPoJu5","outputId":"2f255aa5-f20a-4212-b326-0f6cd6c9b435"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape: (56745, 4)\n"]}],"source":["# ----------------------------------------------\n","# Sampling: Train\n","# ----------------------------------------------\n","train = twitter.rename(columns={'tweet':'comment_text', 'pseudo_label':'target'})\n","print(f'shape: {train.shape}')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1644160173456,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"OfA5WrkCtbSm","outputId":"1f715658-4253-43ed-c8fa-d5aa982c0afc"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-af84012f-e271-476e-b1ba-65962a964a12\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Toxicity</th>\n","      <th>comment_text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>-0.063260</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>-0.621950</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>-0.131646</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td>-0.405339</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>-0.658090</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af84012f-e271-476e-b1ba-65962a964a12')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-af84012f-e271-476e-b1ba-65962a964a12 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-af84012f-e271-476e-b1ba-65962a964a12');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0  ...    target\n","0           0  ... -0.063260\n","1           1  ... -0.621950\n","2           2  ... -0.131646\n","3           3  ... -0.405339\n","4           4  ... -0.658090\n","\n","[5 rows x 4 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1644160173456,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"iCz8KheSQhls"},"outputs":[],"source":["from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n","\n","train['sc_grp'] = pd.cut(train['target'], 10)\n","grp_to_num = {v:n for n, v in enumerate(train['sc_grp'].unique().sort_values())}\n","train['sc_grp'] = train['sc_grp'].map(grp_to_num)\n","\n","kf = StratifiedKFold(n_splits=FOLDS, random_state=SEED, shuffle=True)\n","\n","for fold, (_, val_) in enumerate(kf.split(X=train, y=train['sc_grp'])):\n","  train.loc[val_, 'kfold'] = int(fold)\n","\n","if DEBUG:\n","  train = train.sample(100)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1644160173457,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"9bEtqpdcRI_1","outputId":"038a198e-1edb-4a03-dfda-627a9788b3b5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-24b1ea29-eefc-47b0-b151-b8de88ffb148\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>mean</th>\n","    </tr>\n","    <tr>\n","      <th>kfold</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>11349</td>\n","      <td>-0.123472</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>11349</td>\n","      <td>-0.123142</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>11349</td>\n","      <td>-0.122904</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>11349</td>\n","      <td>-0.124516</td>\n","    </tr>\n","    <tr>\n","      <th>4.0</th>\n","      <td>11349</td>\n","      <td>-0.122794</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24b1ea29-eefc-47b0-b151-b8de88ffb148')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-24b1ea29-eefc-47b0-b151-b8de88ffb148 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-24b1ea29-eefc-47b0-b151-b8de88ffb148');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       count      mean\n","kfold                 \n","0.0    11349 -0.123472\n","1.0    11349 -0.123142\n","2.0    11349 -0.122904\n","3.0    11349 -0.124516\n","4.0    11349 -0.122794"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train.groupby('kfold')['target'].agg(['count', 'mean'])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1644160173457,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"eywJHhMARdS3","outputId":"c09b70b6-e7a8-46f2-8ee3-df9021443343"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train['kfold'].isnull().sum()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["d3490f81ad924eeb9cadb862268d8f63","9a1de4144e834f699de72979403124a2","5163e57a964b4af6801d08aec2db076d","e2883701461148c3bda2c6cba01ff647","e9e7d6d843454c6db4fd060a5756778a","dd6fb1c0dd0149279318bfe8a6684e5b","2e053ffa6fee4f66ac1218f6d9441df2","5804b0854c294950a3a376b9425f6d8e","df59c3f7e68c414993eb151d3c8f0611","bdc823b669714eef9becd0bfc50e8cb0","0e0fc0e3236747a59d0b8986ab0f7b15","8ca50feee5a54faebee45f84c7eca62d","f97d26a9c9b1442388fa8f082fb37685","b5e822ca47894a8689fb3d9d38a10537","ab7acbc61b1e42239b37b8d7c3c8542d","2b9ea8d23fcd4d00a6a045130c56bd23","c949e0d44b1e45838dd85a56e1c4abe8","cf056ae0e1014506b54bc628bf12a1d5","c36bfcaba0a7491083b3a6f40d259658","7b511ef31fb04c18b25baeddca6ba042","481a1ba11dd9422cb67f0ccc44686f95","8c26b70c9da4400eb5c8c5732d8fd5c7","003298ae717145648346ab6ecc9aacb1","3e0d62ac215b4e00ab3ae16ae7334831","e66a8671e3d24f3a940220568bea2a7e","1e96954d891e4030a307e815d09e356f","0631c2a5c9b44c41ac0f593c9e7097ef","1ab175e4a17e4b5a819da0bbaee05f52","ff0e3131fa25497e94342f0afe64a819","0c68e8aa30764906a56816e0ee495d9b","66ae8795646a4298bcd96a0c033cc6ae","562f778204b54fed8230d98757fc1f97","4868893c74224417ba0f1111f6859926","05b8528bf38044038e00b8284c172ef5","301c04bc370d4e6895e4f8772a10f2ae","d28eb491b36c4d929112987c532adbfd","c7e585f5a4dd4fb6917206112fad7ce8","cdbdec203b1b4cbfb598c8f07a317e77","0acdccfb338541e48756ad6f553ec646","be47369ceb21478cbc934c6ca7ea0db2","35c0a12bb1d34d67acc2bdabf75e9996","84986eac783a4de799fde7f902228e2b","dc11ae6f211941feb4f1729456b894c4","a485ce636c4649cfa8c381b2654d84be"]},"executionInfo":{"elapsed":7627,"status":"ok","timestamp":1644160181076,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"6rHp6VNuyMwU","outputId":"af32c713-3723-4fcf-b4f5-258f346d75d9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3490f81ad924eeb9cadb862268d8f63","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/211 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ca50feee5a54faebee45f84c7eca62d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/635 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"003298ae717145648346ab6ecc9aacb1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05b8528bf38044038e00b8284c172ef5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["create: tokenizer\n"]}],"source":["# ----------------------------------------------\n","# Create Tokenizer\n","# ----------------------------------------------\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n","print('create: tokenizer')\n","\n","\n","# ----------------------------------------------\n","# Preprocess func\n","# ----------------------------------------------\n","# Preprocess\n","import string\n","import re\n","import collections\n","from bs4 import BeautifulSoup\n","import nltk\n","#nltk.download('stopwords')\n","#nltk.download('averaged_perceptron_tagger')\n","\n","# https://www.kaggle.com/manabendrarout/pytorch-roberta-ranking-baseline-jrstc-train\n","def text_cleaning(text):\n","    '''\n","    Cleans text into a basic form for NLP. Operations include the following:-\n","    1. Remove special charecters like &, #, etc\n","    2. Removes extra spaces\n","    3. Removes embedded URL links\n","    4. Removes HTML tags\n","    5. Removes emojis\n","    \n","    text - Text piece to be cleaned.\n","    '''\n","    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n","    text = template.sub(r'', text)\n","    \n","    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n","    only_text = soup.get_text()\n","    text = only_text\n","    \n","    emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               \"]+\", flags=re.UNICODE)\n","    text = emoji_pattern.sub(r'', text)\n","    \n","    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n","    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n","    text = text.strip() # remove spaces at the beginning and at the end of string\n","\n","    return text\n","\n","\n","def text_normalization(s:pd.Series):\n","    x = s.apply(text_cleaning)\n","    return x\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1644160181077,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"oid6-ii34LZD"},"outputs":[],"source":["# ----------------------------------------------\n","# Dataset Class\n","# ----------------------------------------------\n","class TweetJigsawDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__\n","        \n","        self.df = df\n","        self.inference_only = inference_only\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df['target'].values, dtype=torch.float32)\n","        \n","        self.encoded = tokenizer.batch_encode_plus(\n","            #text_normalization(df['comment_text']).tolist(),\n","            df['comment_text'].tolist(),\n","            padding='max_length',\n","            max_length=MAX_LEN,\n","            truncation=True,\n","            return_attention_mask=True\n","        )\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return {'input_ids': input_ids,\n","                    'attention_mask': attention_mask\n","                    }\n","        else:\n","            target = self.target[index]\n","            return {'input_ids': input_ids,\n","                    'attention_mask': attention_mask, \n","                    'target': target}\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1644160181077,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"-NHRehe1yQoP"},"outputs":[],"source":["# ----------------------------------------------\n","# Model Class\n","# ----------------------------------------------\n","class AttentionHead(nn.Module):\n","    def __init__(self, in_features, hidden_dim, num_targets):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.middle_features = hidden_dim\n","        self.W = nn.Linear(in_features, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","        self.out_features = hidden_dim\n","\n","    def forward(self, features):\n","        att = torch.tanh(self.W(features))\n","        score = self.V(att)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * features\n","        context_vector = torch.sum(context_vector, dim=1)\n","\n","        return context_vector\n","\n","class TweetJigsawModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.config = AutoConfig.from_pretrained(PRETRAINED)\n","        self.config.attention_probs_dropout_prob = 0.0\n","        self.config.hidden_dropout_prob = 0.0\n","        self.pre_model = AutoModel.from_pretrained(PRETRAINED, config=self.config)\n","        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size,1)\n","        self.dropout = nn.Dropout(0.3)\n","        self.regressor = nn.Linear(self.config.hidden_size, NUM_CLASSES)\n","    \n","    def forward(self, input_ids, attention_mask):\n","        pre_out = self.pre_model(input_ids=input_ids, attention_mask=attention_mask)\n","        x0 = pre_out['last_hidden_state']\n","        x1 = self.head(x0)\n","        #x2 = self.dropout(x1)\n","        x3 = self.regressor(x1)\n","        return x3"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1644160181077,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"DL-M9418cQ30"},"outputs":[],"source":["#j_ds = TweetJigsawDataset(train)\n","#model = TweetJigsawModel().to(DEVICE)\n","#output = model(j_ds[:2]['input_ids'].to(DEVICE), j_ds[:2]['attention_mask'].to(DEVICE))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1644160181078,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"5qUgTJ_jy4mF"},"outputs":[],"source":["#j_ds[0:2]['target']"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":459,"status":"ok","timestamp":1644160181521,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"NXCNVG2dEkpr"},"outputs":[],"source":["# ----------------------------------------------\n","# func: valid, predict\n","# ----------------------------------------------\n","def valid_mse(model, dataloader):\n","    model.eval()\n","    mse_sum = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","            input_ids = data['input_ids'].to(DEVICE)\n","            attention_mask = data['attention_mask'].to(DEVICE)\n","            target = data['target'].to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask)\n","            \n","            mse_sum += nn.MSELoss(reduction='sum')(output.flatten(), target).item()\n","            \n","    return mse_sum/(len(dataloader.dataset))\n","\n","\n","def valid_bce(model, dataloader):\n","    model.eval()\n","    score_sum = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","            input_ids = data['input_ids'].to(DEVICE)\n","            attention_mask = data['attention_mask'].to(DEVICE)\n","            target = data['target'].to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask)\n","            score_sum += nn.BCELoss(reduction='sum')(output.flatten(), target).item()\n","            \n","    return score_sum/(len(dataloader.dataset))\n","\n","def valid_bcelogit(model, dataloader):\n","    model.eval()\n","    score_sum = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","            input_ids = data['input_ids'].to(DEVICE)\n","            attention_mask = data['attention_mask'].to(DEVICE)\n","            target = data['target'].to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask)\n","            score_sum += nn.BCEWithLogitsLoss(reduction='sum')(output, target).item()\n","            \n","    return score_sum/(len(dataloader.dataset)*target.shape[1])\n","\n","def predict(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), NUM_CLASSES))\n","    idx = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","            input_ids = data['input_ids'].to(DEVICE)\n","            attention_mask = data['attention_mask'].to(DEVICE)\n","            \n","            output = model(input_ids, attention_mask)\n","            result[idx:idx + output.shape[0], :] = output.to('cpu')\n","            \n","            idx += output.shape[0]\n","            \n","    return result\n","\n","\n","# ----------------------------------------------\n","# func: train\n","# ----------------------------------------------\n","def train_fn(\n","    model,\n","    save_path,\n","    train_loader,\n","    val_loader,\n","    optimizer,\n","    scheduler=None,\n","    num_epochs=NUM_EPOCHS\n","):\n","\n","    best_score = np.inf\n","    best_epoch = 0\n","    log_interval = LOG_INTERVAL\n","\n","    start = time.time()\n","\n","    for epoch in range(num_epochs):\n","        val_score = None\n","\n","        for batch_idx, data in enumerate(train_loader):\n","            input_ids = data['input_ids'].to(DEVICE)\n","            attention_mask = data['attention_mask'].to(DEVICE)\n","            target = data['target'].to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            model.train()\n","\n","            output = model(input_ids, attention_mask)\n","            loss = nn.MSELoss()(output.flatten(), target)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            if scheduler:\n","                scheduler.step()\n","\n","            if (batch_idx > 0) & (batch_idx % log_interval == 0):\n","                val_score = valid_mse(model, val_loader)\n","                print(f\"Epoch {epoch+1}, Step {batch_idx+1}, train_loss: {loss:0.5f}, val_loss: {val_score:0.5f}\")\n","                if val_score < best_score:\n","                    print(f\"Model Inproved: {best_score} ----> {val_score}\")\n","                    best_score = val_score\n","                    torch.save(model.state_dict(), save_path)\n","\n","            del input_ids\n","            del attention_mask\n","            del target\n","            del output\n","            torch.cuda.empty_cache()\n","\n","    print(f\"elasped time: {time.time() - start: 0.3}\")\n","    start = time.time()\n","\n","    return best_score\n","\n","\n","# ----------------------------------------------\n","# func: create optimizer\n","# ----------------------------------------------\n","def create_optimizer(model):\n","    named_params = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optim_params = []\n","    for idx_, (name_, params_) in enumerate(named_params):\n","        weight_decay = 0 if name_ in no_decay else 0.01\n","        optim_params.append({'params':params_,\n","                            'weight_decay': weight_decay,\n","                            })\n","\n","    return AdamW(optim_params)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644160181521,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"EnJXZkrD6t5z"},"outputs":[],"source":["# ----------------------------------------------\n","# func: Validation\n","# ----------------------------------------------\n","def calc_val_in_step(model, less_dataset, more_dataset):\n","    less_loader = DataLoader(less_dataset, batch_size=BATCH_SIZE,\n","                             drop_last=False, shuffle=False, num_workers=2)\n","    more_loader = DataLoader(more_dataset, batch_size=BATCH_SIZE,\n","                             drop_last=False, shuffle=False, num_workers=2)\n","\n","    less_pred = predict(model, less_loader)\n","    more_pred = predict(model, more_loader)\n","    acc = (less_pred < more_pred).sum() / len(less_pred)\n","    print(f\"accuracy: {acc}\")\n","    print(f\"{(less_pred < more_pred).sum()} / {len(less_pred)}\")\n","    #return less_pred, more_pred"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0f1ae8ce8dc24539879aca98b44ff0ce","5bf6283b390d40b2b07aaf8901d46aa7","d6096fc85ac64016bb65e85f87a446cf","679662ac6cd4433fa9fcc5690650ec1b","a44e6e3deb724ae2bd2a9a4e6357026c","e9f3ea5643b04654a02a1ba01e991a1e","00e8ef3b865e49a68a11833ee8ca59af","6567c378e87f405c82dc74fe0324a33b","115845e94c6242699d817e6e2289c6f1","30aedff7992b42628d45218396deb47b","27fc894e924a404092a805ed5e70bb69"]},"executionInfo":{"elapsed":25768724,"status":"ok","timestamp":1644185950242,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"RlJqN5Jwv6zT","outputId":"7298064f-c5c2-4699-f0be-fc7f5f0cf742"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** FOLD 1 / 5***\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f1ae8ce8dc24539879aca98b44ff0ce","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 101, train_loss: 0.01709, val_loss: 0.01575\n","Model Inproved: inf ----> 0.015745844069304724\n","Epoch 1, Step 201, train_loss: 0.00414, val_loss: 0.00505\n","Model Inproved: 0.015745844069304724 ----> 0.005046741718373663\n","Epoch 1, Step 301, train_loss: 0.00338, val_loss: 0.00279\n","Model Inproved: 0.005046741718373663 ----> 0.002787921366135983\n","Epoch 1, Step 401, train_loss: 0.00137, val_loss: 0.00166\n","Model Inproved: 0.002787921366135983 ----> 0.001659630286720752\n","Epoch 1, Step 501, train_loss: 0.00108, val_loss: 0.00125\n","Model Inproved: 0.001659630286720752 ----> 0.001249553542986285\n","Epoch 1, Step 601, train_loss: 0.00114, val_loss: 0.00099\n","Model Inproved: 0.001249553542986285 ----> 0.000988085376114672\n","Epoch 1, Step 701, train_loss: 0.00074, val_loss: 0.00086\n","Model Inproved: 0.000988085376114672 ----> 0.0008552674404260519\n","Epoch 1, Step 801, train_loss: 0.00071, val_loss: 0.00077\n","Model Inproved: 0.0008552674404260519 ----> 0.0007716154000633327\n","Epoch 1, Step 901, train_loss: 0.00068, val_loss: 0.00064\n","Model Inproved: 0.0007716154000633327 ----> 0.0006387302291666776\n","Epoch 1, Step 1001, train_loss: 0.00040, val_loss: 0.00058\n","Model Inproved: 0.0006387302291666776 ----> 0.0005812652940059396\n","Epoch 1, Step 1101, train_loss: 0.00053, val_loss: 0.00052\n","Model Inproved: 0.0005812652940059396 ----> 0.0005170390340097886\n","Epoch 1, Step 1201, train_loss: 0.00098, val_loss: 0.00051\n","Model Inproved: 0.0005170390340097886 ----> 0.0005137371664548568\n","Epoch 1, Step 1301, train_loss: 0.00031, val_loss: 0.00047\n","Model Inproved: 0.0005137371664548568 ----> 0.00047126646278855566\n","Epoch 1, Step 1401, train_loss: 0.00037, val_loss: 0.00039\n","Model Inproved: 0.00047126646278855566 ----> 0.0003919093430594381\n","Epoch 2, Step 101, train_loss: 0.00027, val_loss: 0.00048\n","Epoch 2, Step 201, train_loss: 0.00029, val_loss: 0.00040\n","Epoch 2, Step 301, train_loss: 0.00051, val_loss: 0.00040\n","Epoch 2, Step 401, train_loss: 0.00022, val_loss: 0.00037\n","Model Inproved: 0.0003919093430594381 ----> 0.00036914982667695203\n","Epoch 2, Step 501, train_loss: 0.00027, val_loss: 0.00039\n","Epoch 2, Step 601, train_loss: 0.00030, val_loss: 0.00042\n","Epoch 2, Step 701, train_loss: 0.00015, val_loss: 0.00041\n","Epoch 2, Step 801, train_loss: 0.00033, val_loss: 0.00044\n","Epoch 2, Step 901, train_loss: 0.00016, val_loss: 0.00042\n","Epoch 2, Step 1001, train_loss: 0.00024, val_loss: 0.00040\n","Epoch 2, Step 1101, train_loss: 0.00017, val_loss: 0.00039\n","Epoch 2, Step 1201, train_loss: 0.00060, val_loss: 0.00038\n","Epoch 2, Step 1301, train_loss: 0.00028, val_loss: 0.00042\n","Epoch 2, Step 1401, train_loss: 0.00014, val_loss: 0.00035\n","Model Inproved: 0.00036914982667695203 ----> 0.00035342007382413513\n","Epoch 3, Step 101, train_loss: 0.00050, val_loss: 0.00071\n","Epoch 3, Step 201, train_loss: 0.00023, val_loss: 0.00044\n","Epoch 3, Step 301, train_loss: 0.00023, val_loss: 0.00035\n","Model Inproved: 0.00035342007382413513 ----> 0.00034598397361507697\n","Epoch 3, Step 401, train_loss: 0.00018, val_loss: 0.00046\n","Epoch 3, Step 501, train_loss: 0.00032, val_loss: 0.00043\n","Epoch 3, Step 601, train_loss: 0.00023, val_loss: 0.00038\n","Epoch 3, Step 701, train_loss: 0.00026, val_loss: 0.00037\n","Epoch 3, Step 801, train_loss: 0.00013, val_loss: 0.00034\n","Model Inproved: 0.00034598397361507697 ----> 0.0003435094923296997\n","Epoch 3, Step 901, train_loss: 0.00031, val_loss: 0.00047\n","Epoch 3, Step 1001, train_loss: 0.00036, val_loss: 0.00044\n","Epoch 3, Step 1101, train_loss: 0.00015, val_loss: 0.00032\n","Model Inproved: 0.0003435094923296997 ----> 0.00031743246555398613\n","Epoch 3, Step 1201, train_loss: 0.00025, val_loss: 0.00034\n","Epoch 3, Step 1301, train_loss: 0.00021, val_loss: 0.00032\n","Model Inproved: 0.00031743246555398613 ----> 0.00031664150805843695\n","Epoch 3, Step 1401, train_loss: 0.00038, val_loss: 0.00036\n","Epoch 4, Step 101, train_loss: 0.00024, val_loss: 0.00033\n","Epoch 4, Step 201, train_loss: 0.00032, val_loss: 0.00036\n","Epoch 4, Step 301, train_loss: 0.00010, val_loss: 0.00036\n","Epoch 4, Step 401, train_loss: 0.00054, val_loss: 0.00029\n","Model Inproved: 0.00031664150805843695 ----> 0.0002937146347572149\n","Epoch 4, Step 501, train_loss: 0.00026, val_loss: 0.00047\n","Epoch 4, Step 601, train_loss: 0.00019, val_loss: 0.00030\n","Epoch 4, Step 701, train_loss: 0.00031, val_loss: 0.00031\n","Epoch 4, Step 801, train_loss: 0.00009, val_loss: 0.00035\n","Epoch 4, Step 901, train_loss: 0.00019, val_loss: 0.00031\n","Epoch 4, Step 1001, train_loss: 0.00027, val_loss: 0.00031\n","Epoch 4, Step 1101, train_loss: 0.00026, val_loss: 0.00035\n","Epoch 4, Step 1201, train_loss: 0.00010, val_loss: 0.00037\n","Epoch 4, Step 1301, train_loss: 0.00008, val_loss: 0.00026\n","Model Inproved: 0.0002937146347572149 ----> 0.00026282524164506426\n","Epoch 4, Step 1401, train_loss: 0.00010, val_loss: 0.00026\n","Model Inproved: 0.00026282524164506426 ----> 0.000261033899911094\n","Epoch 5, Step 101, train_loss: 0.00009, val_loss: 0.00026\n","Model Inproved: 0.000261033899911094 ----> 0.0002576606343438359\n","Epoch 5, Step 201, train_loss: 0.00005, val_loss: 0.00025\n","Model Inproved: 0.0002576606343438359 ----> 0.0002520932133704836\n","Epoch 5, Step 301, train_loss: 0.00007, val_loss: 0.00025\n","Model Inproved: 0.0002520932133704836 ----> 0.0002473832141479655\n","Epoch 5, Step 401, train_loss: 0.00009, val_loss: 0.00026\n","Epoch 5, Step 501, train_loss: 0.00005, val_loss: 0.00024\n","Model Inproved: 0.0002473832141479655 ----> 0.000235069452660057\n","Epoch 5, Step 601, train_loss: 0.00005, val_loss: 0.00024\n","Epoch 5, Step 701, train_loss: 0.00006, val_loss: 0.00024\n","Epoch 5, Step 801, train_loss: 0.00004, val_loss: 0.00023\n","Model Inproved: 0.000235069452660057 ----> 0.00022952806797496997\n","Epoch 5, Step 901, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 5, Step 1001, train_loss: 0.00007, val_loss: 0.00022\n","Model Inproved: 0.00022952806797496997 ----> 0.00022499651585901134\n","Epoch 5, Step 1101, train_loss: 0.00004, val_loss: 0.00023\n","Epoch 5, Step 1201, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 5, Step 1301, train_loss: 0.00007, val_loss: 0.00022\n","Model Inproved: 0.00022499651585901134 ----> 0.00022276238607380074\n","Epoch 5, Step 1401, train_loss: 0.00006, val_loss: 0.00022\n","Epoch 6, Step 101, train_loss: 0.00004, val_loss: 0.00022\n","Model Inproved: 0.00022276238607380074 ----> 0.00021782763408104226\n","Epoch 6, Step 201, train_loss: 0.00004, val_loss: 0.00022\n","Epoch 6, Step 301, train_loss: 0.00006, val_loss: 0.00022\n","Epoch 6, Step 401, train_loss: 0.00003, val_loss: 0.00022\n","Epoch 6, Step 501, train_loss: 0.00005, val_loss: 0.00022\n","Model Inproved: 0.00021782763408104226 ----> 0.00021599581610703218\n","Epoch 6, Step 601, train_loss: 0.00002, val_loss: 0.00022\n","Model Inproved: 0.00021599581610703218 ----> 0.00021502700432653657\n","Epoch 6, Step 701, train_loss: 0.00003, val_loss: 0.00022\n","Epoch 6, Step 801, train_loss: 0.00005, val_loss: 0.00022\n","Epoch 6, Step 901, train_loss: 0.00002, val_loss: 0.00021\n","Model Inproved: 0.00021502700432653657 ----> 0.00021491127736710227\n","Epoch 6, Step 1001, train_loss: 0.00002, val_loss: 0.00022\n","Epoch 6, Step 1101, train_loss: 0.00001, val_loss: 0.00021\n","Model Inproved: 0.00021491127736710227 ----> 0.00021455306739106753\n","Epoch 6, Step 1201, train_loss: 0.00003, val_loss: 0.00021\n","Epoch 6, Step 1301, train_loss: 0.00002, val_loss: 0.00021\n","Epoch 6, Step 1401, train_loss: 0.00003, val_loss: 0.00021\n","elasped time:  4.78e+03\n","accuracy: 0.7141291351135911\n","21501 / 30108\n","[0.00021455306739106753]\n","Mean: 0.00021455306739106753\n","*** FOLD 2 / 5***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 101, train_loss: 0.00376, val_loss: 0.00358\n","Model Inproved: inf ----> 0.0035820825292797527\n","Epoch 1, Step 201, train_loss: 0.00176, val_loss: 0.00184\n","Model Inproved: 0.0035820825292797527 ----> 0.001836736148446654\n","Epoch 1, Step 301, train_loss: 0.00094, val_loss: 0.00092\n","Model Inproved: 0.001836736148446654 ----> 0.0009230783168009508\n","Epoch 1, Step 401, train_loss: 0.00043, val_loss: 0.00066\n","Model Inproved: 0.0009230783168009508 ----> 0.000663347098658301\n","Epoch 1, Step 501, train_loss: 0.00082, val_loss: 0.00060\n","Model Inproved: 0.000663347098658301 ----> 0.0006037658615585482\n","Epoch 1, Step 601, train_loss: 0.00038, val_loss: 0.00055\n","Model Inproved: 0.0006037658615585482 ----> 0.0005485962506267786\n","Epoch 1, Step 701, train_loss: 0.00036, val_loss: 0.00041\n","Model Inproved: 0.0005485962506267786 ----> 0.00040991978042982457\n","Epoch 1, Step 801, train_loss: 0.00022, val_loss: 0.00035\n","Model Inproved: 0.00040991978042982457 ----> 0.00034683232986507665\n","Epoch 1, Step 901, train_loss: 0.00039, val_loss: 0.00031\n","Model Inproved: 0.00034683232986507665 ----> 0.00031448917292568564\n","Epoch 1, Step 1001, train_loss: 0.00032, val_loss: 0.00037\n","Epoch 1, Step 1101, train_loss: 0.00022, val_loss: 0.00038\n","Epoch 1, Step 1201, train_loss: 0.00025, val_loss: 0.00031\n","Model Inproved: 0.00031448917292568564 ----> 0.000310841194505074\n","Epoch 1, Step 1301, train_loss: 0.00048, val_loss: 0.00035\n","Epoch 1, Step 1401, train_loss: 0.00018, val_loss: 0.00031\n","Model Inproved: 0.000310841194505074 ----> 0.0003070448882958576\n","Epoch 2, Step 101, train_loss: 0.00021, val_loss: 0.00028\n","Model Inproved: 0.0003070448882958576 ----> 0.00028013880764649496\n","Epoch 2, Step 201, train_loss: 0.00254, val_loss: 0.00029\n","Epoch 2, Step 301, train_loss: 0.00034, val_loss: 0.00036\n","Epoch 2, Step 401, train_loss: 0.00020, val_loss: 0.00036\n","Epoch 2, Step 501, train_loss: 0.00012, val_loss: 0.00030\n","Epoch 2, Step 601, train_loss: 0.00096, val_loss: 0.00031\n","Epoch 2, Step 701, train_loss: 0.00019, val_loss: 0.00035\n","Epoch 2, Step 801, train_loss: 0.00025, val_loss: 0.00036\n","Epoch 2, Step 901, train_loss: 0.00039, val_loss: 0.00039\n","Epoch 2, Step 1001, train_loss: 0.00023, val_loss: 0.00036\n","Epoch 2, Step 1101, train_loss: 0.00037, val_loss: 0.00083\n","Epoch 2, Step 1201, train_loss: 0.00037, val_loss: 0.00042\n","Epoch 2, Step 1301, train_loss: 0.00048, val_loss: 0.00043\n","Epoch 2, Step 1401, train_loss: 0.00024, val_loss: 0.00036\n","Epoch 3, Step 101, train_loss: 0.00092, val_loss: 0.00050\n","Epoch 3, Step 201, train_loss: 0.00064, val_loss: 0.00041\n","Epoch 3, Step 301, train_loss: 0.00015, val_loss: 0.00038\n","Epoch 3, Step 401, train_loss: 0.00075, val_loss: 0.00047\n","Epoch 3, Step 501, train_loss: 0.00025, val_loss: 0.00038\n","Epoch 3, Step 601, train_loss: 0.00026, val_loss: 0.00037\n","Epoch 3, Step 701, train_loss: 0.00021, val_loss: 0.00045\n","Epoch 3, Step 801, train_loss: 0.00216, val_loss: 0.00035\n","Epoch 3, Step 901, train_loss: 0.00042, val_loss: 0.00035\n","Epoch 3, Step 1001, train_loss: 0.00079, val_loss: 0.00044\n","Epoch 3, Step 1101, train_loss: 0.00029, val_loss: 0.00033\n","Epoch 3, Step 1201, train_loss: 0.00061, val_loss: 0.00035\n","Epoch 3, Step 1301, train_loss: 0.00020, val_loss: 0.00036\n","Epoch 3, Step 1401, train_loss: 0.00019, val_loss: 0.00045\n","Epoch 4, Step 101, train_loss: 0.00021, val_loss: 0.00030\n","Epoch 4, Step 201, train_loss: 0.00028, val_loss: 0.00037\n","Epoch 4, Step 301, train_loss: 0.00018, val_loss: 0.00031\n","Epoch 4, Step 401, train_loss: 0.00136, val_loss: 0.00027\n","Model Inproved: 0.00028013880764649496 ----> 0.0002732716857072687\n","Epoch 4, Step 501, train_loss: 0.00019, val_loss: 0.00026\n","Model Inproved: 0.0002732716857072687 ----> 0.0002639796012358986\n","Epoch 4, Step 601, train_loss: 0.00018, val_loss: 0.00025\n","Model Inproved: 0.0002639796012358986 ----> 0.00024732678462877176\n","Epoch 4, Step 701, train_loss: 0.00008, val_loss: 0.00025\n","Epoch 4, Step 801, train_loss: 0.00033, val_loss: 0.00024\n","Model Inproved: 0.00024732678462877176 ----> 0.00024194903124387395\n","Epoch 4, Step 901, train_loss: 0.00025, val_loss: 0.00027\n","Epoch 4, Step 1001, train_loss: 0.00023, val_loss: 0.00026\n","Epoch 4, Step 1101, train_loss: 0.00020, val_loss: 0.00026\n","Epoch 4, Step 1201, train_loss: 0.00027, val_loss: 0.00024\n","Epoch 4, Step 1301, train_loss: 0.00019, val_loss: 0.00024\n","Model Inproved: 0.00024194903124387395 ----> 0.0002350647723517576\n","Epoch 4, Step 1401, train_loss: 0.00040, val_loss: 0.00024\n","Epoch 5, Step 101, train_loss: 0.00004, val_loss: 0.00022\n","Model Inproved: 0.0002350647723517576 ----> 0.0002178637728476479\n","Epoch 5, Step 201, train_loss: 0.00003, val_loss: 0.00022\n","Model Inproved: 0.0002178637728476479 ----> 0.00021501965933419545\n","Epoch 5, Step 301, train_loss: 0.00009, val_loss: 0.00021\n","Model Inproved: 0.00021501965933419545 ----> 0.00020857689928774508\n","Epoch 5, Step 401, train_loss: 0.00005, val_loss: 0.00021\n","Model Inproved: 0.00020857689928774508 ----> 0.00020767377150086714\n","Epoch 5, Step 501, train_loss: 0.00006, val_loss: 0.00021\n","Epoch 5, Step 601, train_loss: 0.00014, val_loss: 0.00021\n","Model Inproved: 0.00020767377150086714 ----> 0.00020575098855976835\n","Epoch 5, Step 701, train_loss: 0.00013, val_loss: 0.00020\n","Model Inproved: 0.00020575098855976835 ----> 0.00020394887387972788\n","Epoch 5, Step 801, train_loss: 0.00005, val_loss: 0.00021\n","Epoch 5, Step 901, train_loss: 0.00009, val_loss: 0.00020\n","Model Inproved: 0.00020394887387972788 ----> 0.00019990244680251283\n","Epoch 5, Step 1001, train_loss: 0.00008, val_loss: 0.00020\n","Epoch 5, Step 1101, train_loss: 0.00008, val_loss: 0.00021\n","Epoch 5, Step 1201, train_loss: 0.00005, val_loss: 0.00019\n","Model Inproved: 0.00019990244680251283 ----> 0.00019483595836376847\n","Epoch 5, Step 1301, train_loss: 0.00006, val_loss: 0.00019\n","Model Inproved: 0.00019483595836376847 ----> 0.0001929804963240342\n","Epoch 5, Step 1401, train_loss: 0.00005, val_loss: 0.00019\n","Model Inproved: 0.0001929804963240342 ----> 0.0001924270700702882\n","Epoch 6, Step 101, train_loss: 0.00003, val_loss: 0.00019\n","Epoch 6, Step 201, train_loss: 0.00002, val_loss: 0.00019\n","Model Inproved: 0.0001924270700702882 ----> 0.00019150918899808912\n","Epoch 6, Step 301, train_loss: 0.00003, val_loss: 0.00019\n","Model Inproved: 0.00019150918899808912 ----> 0.00018875260816409256\n","Epoch 6, Step 401, train_loss: 0.00002, val_loss: 0.00019\n","Epoch 6, Step 501, train_loss: 0.00002, val_loss: 0.00019\n","Epoch 6, Step 601, train_loss: 0.00003, val_loss: 0.00019\n","Model Inproved: 0.00018875260816409256 ----> 0.00018783533076108808\n","Epoch 6, Step 701, train_loss: 0.00003, val_loss: 0.00019\n","Model Inproved: 0.00018783533076108808 ----> 0.00018764473329640314\n","Epoch 6, Step 801, train_loss: 0.00004, val_loss: 0.00019\n","Model Inproved: 0.00018764473329640314 ----> 0.00018706532618732865\n","Epoch 6, Step 901, train_loss: 0.00004, val_loss: 0.00019\n","Epoch 6, Step 1001, train_loss: 0.00004, val_loss: 0.00019\n","Epoch 6, Step 1101, train_loss: 0.00003, val_loss: 0.00019\n","Model Inproved: 0.00018706532618732865 ----> 0.00018704181483650742\n","Epoch 6, Step 1201, train_loss: 0.00002, val_loss: 0.00019\n","Model Inproved: 0.00018704181483650742 ----> 0.00018674067664881306\n","Epoch 6, Step 1301, train_loss: 0.00002, val_loss: 0.00019\n","Epoch 6, Step 1401, train_loss: 0.00002, val_loss: 0.00019\n","elasped time:  5.09e+03\n","accuracy: 0.7131327222000797\n","21471 / 30108\n","[0.00021455306739106753, 0.00018674067664881306]\n","Mean: 0.0002006468720199403\n","*** FOLD 3 / 5***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 101, train_loss: 0.00294, val_loss: 0.00211\n","Model Inproved: inf ----> 0.0021132013743848503\n","Epoch 1, Step 201, train_loss: 0.00071, val_loss: 0.00108\n","Model Inproved: 0.0021132013743848503 ----> 0.0010774535995939512\n","Epoch 1, Step 301, train_loss: 0.00053, val_loss: 0.00071\n","Model Inproved: 0.0010774535995939512 ----> 0.0007070938868899315\n","Epoch 1, Step 401, train_loss: 0.00036, val_loss: 0.00049\n","Model Inproved: 0.0007070938868899315 ----> 0.0004914198983294899\n","Epoch 1, Step 501, train_loss: 0.00074, val_loss: 0.00048\n","Model Inproved: 0.0004914198983294899 ----> 0.00048483140175855705\n","Epoch 1, Step 601, train_loss: 0.00044, val_loss: 0.00058\n","Epoch 1, Step 701, train_loss: 0.00039, val_loss: 0.00036\n","Model Inproved: 0.00048483140175855705 ----> 0.00035576519789974305\n","Epoch 1, Step 801, train_loss: 0.00056, val_loss: 0.00047\n","Epoch 1, Step 901, train_loss: 0.00018, val_loss: 0.00034\n","Model Inproved: 0.00035576519789974305 ----> 0.0003439142684754963\n","Epoch 1, Step 1001, train_loss: 0.00027, val_loss: 0.00036\n","Epoch 1, Step 1101, train_loss: 0.00055, val_loss: 0.00037\n","Epoch 1, Step 1201, train_loss: 0.00021, val_loss: 0.00035\n","Epoch 1, Step 1301, train_loss: 0.00036, val_loss: 0.00036\n","Epoch 1, Step 1401, train_loss: 0.00032, val_loss: 0.00052\n","Epoch 2, Step 101, train_loss: 0.00087, val_loss: 0.00060\n","Epoch 2, Step 201, train_loss: 0.00035, val_loss: 0.00065\n","Epoch 2, Step 301, train_loss: 0.00021, val_loss: 0.00054\n","Epoch 2, Step 401, train_loss: 0.00122, val_loss: 0.00076\n","Epoch 2, Step 501, train_loss: 0.00108, val_loss: 0.00054\n","Epoch 2, Step 601, train_loss: 0.00071, val_loss: 0.00083\n","Epoch 2, Step 701, train_loss: 0.00111, val_loss: 0.00068\n","Epoch 2, Step 801, train_loss: 0.00129, val_loss: 0.00077\n","Epoch 2, Step 901, train_loss: 0.00053, val_loss: 0.00070\n","Epoch 2, Step 1001, train_loss: 0.00033, val_loss: 0.00054\n","Epoch 2, Step 1101, train_loss: 0.00106, val_loss: 0.00060\n","Epoch 2, Step 1201, train_loss: 0.00069, val_loss: 0.00058\n","Epoch 2, Step 1301, train_loss: 0.00048, val_loss: 0.00063\n","Epoch 2, Step 1401, train_loss: 0.00057, val_loss: 0.00074\n","Epoch 3, Step 101, train_loss: 0.00335, val_loss: 0.00063\n","Epoch 3, Step 201, train_loss: 0.00087, val_loss: 0.00049\n","Epoch 3, Step 301, train_loss: 0.00060, val_loss: 0.00080\n","Epoch 3, Step 401, train_loss: 0.00023, val_loss: 0.00050\n","Epoch 3, Step 501, train_loss: 0.00055, val_loss: 0.00048\n","Epoch 3, Step 601, train_loss: 0.00028, val_loss: 0.00051\n","Epoch 3, Step 701, train_loss: 0.00021, val_loss: 0.00050\n","Epoch 3, Step 801, train_loss: 0.00018, val_loss: 0.00045\n","Epoch 3, Step 901, train_loss: 0.00097, val_loss: 0.00052\n","Epoch 3, Step 1001, train_loss: 0.00036, val_loss: 0.00043\n","Epoch 3, Step 1101, train_loss: 0.00038, val_loss: 0.00043\n","Epoch 3, Step 1201, train_loss: 0.00093, val_loss: 0.00045\n","Epoch 3, Step 1301, train_loss: 0.00022, val_loss: 0.00042\n","Epoch 3, Step 1401, train_loss: 0.00036, val_loss: 0.00040\n","Epoch 4, Step 101, train_loss: 0.00021, val_loss: 0.00040\n","Epoch 4, Step 201, train_loss: 0.00043, val_loss: 0.00037\n","Epoch 4, Step 301, train_loss: 0.00030, val_loss: 0.00039\n","Epoch 4, Step 401, train_loss: 0.00072, val_loss: 0.00039\n","Epoch 4, Step 501, train_loss: 0.00008, val_loss: 0.00035\n","Epoch 4, Step 601, train_loss: 0.00010, val_loss: 0.00034\n","Epoch 4, Step 701, train_loss: 0.00016, val_loss: 0.00034\n","Model Inproved: 0.0003439142684754963 ----> 0.00033740473113768937\n","Epoch 4, Step 801, train_loss: 0.00024, val_loss: 0.00037\n","Epoch 4, Step 901, train_loss: 0.00014, val_loss: 0.00033\n","Model Inproved: 0.00033740473113768937 ----> 0.0003331602015670007\n","Epoch 4, Step 1001, train_loss: 0.00021, val_loss: 0.00037\n","Epoch 4, Step 1101, train_loss: 0.00012, val_loss: 0.00037\n","Epoch 4, Step 1201, train_loss: 0.00014, val_loss: 0.00035\n","Epoch 4, Step 1301, train_loss: 0.00009, val_loss: 0.00032\n","Model Inproved: 0.0003331602015670007 ----> 0.0003165476044584307\n","Epoch 4, Step 1401, train_loss: 0.00015, val_loss: 0.00029\n","Model Inproved: 0.0003165476044584307 ----> 0.0002912212028135727\n","Epoch 5, Step 101, train_loss: 0.00004, val_loss: 0.00030\n","Epoch 5, Step 201, train_loss: 0.00011, val_loss: 0.00028\n","Model Inproved: 0.0002912212028135727 ----> 0.00028487113600270017\n","Epoch 5, Step 301, train_loss: 0.00005, val_loss: 0.00030\n","Epoch 5, Step 401, train_loss: 0.00005, val_loss: 0.00028\n","Model Inproved: 0.00028487113600270017 ----> 0.00028001605501879823\n","Epoch 5, Step 501, train_loss: 0.00012, val_loss: 0.00028\n","Model Inproved: 0.00028001605501879823 ----> 0.0002797442763464942\n","Epoch 5, Step 601, train_loss: 0.00007, val_loss: 0.00028\n","Model Inproved: 0.0002797442763464942 ----> 0.0002782040652852213\n","Epoch 5, Step 701, train_loss: 0.00005, val_loss: 0.00028\n","Model Inproved: 0.0002782040652852213 ----> 0.0002781724238387288\n","Epoch 5, Step 801, train_loss: 0.00006, val_loss: 0.00028\n","Model Inproved: 0.0002781724238387288 ----> 0.00027696220561409336\n","Epoch 5, Step 901, train_loss: 0.00004, val_loss: 0.00028\n","Epoch 5, Step 1001, train_loss: 0.00006, val_loss: 0.00027\n","Model Inproved: 0.00027696220561409336 ----> 0.00027342955472085817\n","Epoch 5, Step 1101, train_loss: 0.00004, val_loss: 0.00027\n","Model Inproved: 0.00027342955472085817 ----> 0.0002687828368424033\n","Epoch 5, Step 1201, train_loss: 0.00010, val_loss: 0.00027\n","Epoch 5, Step 1301, train_loss: 0.00002, val_loss: 0.00027\n","Model Inproved: 0.0002687828368424033 ----> 0.00026664999509575736\n","Epoch 5, Step 1401, train_loss: 0.00005, val_loss: 0.00028\n","Epoch 6, Step 101, train_loss: 0.00003, val_loss: 0.00026\n","Model Inproved: 0.00026664999509575736 ----> 0.00026294205060844333\n","Epoch 6, Step 201, train_loss: 0.00004, val_loss: 0.00027\n","Epoch 6, Step 301, train_loss: 0.00003, val_loss: 0.00026\n","Model Inproved: 0.00026294205060844333 ----> 0.0002586863836334605\n","Epoch 6, Step 401, train_loss: 0.00002, val_loss: 0.00027\n","Epoch 6, Step 501, train_loss: 0.00002, val_loss: 0.00026\n","Epoch 6, Step 601, train_loss: 0.00005, val_loss: 0.00026\n","Epoch 6, Step 701, train_loss: 0.00004, val_loss: 0.00026\n","Epoch 6, Step 801, train_loss: 0.00002, val_loss: 0.00026\n","Epoch 6, Step 901, train_loss: 0.00007, val_loss: 0.00026\n","Epoch 6, Step 1001, train_loss: 0.00004, val_loss: 0.00026\n","Epoch 6, Step 1101, train_loss: 0.00002, val_loss: 0.00026\n","Epoch 6, Step 1201, train_loss: 0.00003, val_loss: 0.00026\n","Epoch 6, Step 1301, train_loss: 0.00003, val_loss: 0.00026\n","Epoch 6, Step 1401, train_loss: 0.00003, val_loss: 0.00026\n","elasped time:  5.05e+03\n","accuracy: 0.7136973561844028\n","21488 / 30108\n","[0.00021455306739106753, 0.00018674067664881306, 0.0002586863836334605]\n","Mean: 0.0002199933758911137\n","*** FOLD 4 / 5***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 101, train_loss: 0.00129, val_loss: 0.00337\n","Model Inproved: inf ----> 0.003372309498205953\n","Epoch 1, Step 201, train_loss: 0.00222, val_loss: 0.00145\n","Model Inproved: 0.003372309498205953 ----> 0.001448830841746779\n","Epoch 1, Step 301, train_loss: 0.00163, val_loss: 0.00110\n","Model Inproved: 0.001448830841746779 ----> 0.0010979645954048974\n","Epoch 1, Step 401, train_loss: 0.00065, val_loss: 0.00071\n","Model Inproved: 0.0010979645954048974 ----> 0.0007133790169080923\n","Epoch 1, Step 501, train_loss: 0.00035, val_loss: 0.00057\n","Model Inproved: 0.0007133790169080923 ----> 0.0005680551949889453\n","Epoch 1, Step 601, train_loss: 0.00022, val_loss: 0.00044\n","Model Inproved: 0.0005680551949889453 ----> 0.00043695815430614527\n","Epoch 1, Step 701, train_loss: 0.00038, val_loss: 0.00039\n","Model Inproved: 0.00043695815430614527 ----> 0.0003891122276802921\n","Epoch 1, Step 801, train_loss: 0.00040, val_loss: 0.00040\n","Epoch 1, Step 901, train_loss: 0.00025, val_loss: 0.00038\n","Model Inproved: 0.0003891122276802921 ----> 0.0003828737761338531\n","Epoch 1, Step 1001, train_loss: 0.00025, val_loss: 0.00037\n","Model Inproved: 0.0003828737761338531 ----> 0.0003683985982666967\n","Epoch 1, Step 1101, train_loss: 0.00026, val_loss: 0.00039\n","Epoch 1, Step 1201, train_loss: 0.00032, val_loss: 0.00030\n","Model Inproved: 0.0003683985982666967 ----> 0.0003038512718292551\n","Epoch 1, Step 1301, train_loss: 0.00020, val_loss: 0.00031\n","Epoch 1, Step 1401, train_loss: 0.00019, val_loss: 0.00037\n","Epoch 2, Step 101, train_loss: 0.00032, val_loss: 0.00038\n","Epoch 2, Step 201, train_loss: 0.00034, val_loss: 0.00038\n","Epoch 2, Step 301, train_loss: 0.00022, val_loss: 0.00041\n","Epoch 2, Step 401, train_loss: 0.00028, val_loss: 0.00040\n","Epoch 2, Step 501, train_loss: 0.00044, val_loss: 0.00070\n","Epoch 2, Step 601, train_loss: 0.00029, val_loss: 0.00052\n","Epoch 2, Step 701, train_loss: 0.00036, val_loss: 0.00044\n","Epoch 2, Step 801, train_loss: 0.00064, val_loss: 0.00041\n","Epoch 2, Step 901, train_loss: 0.00065, val_loss: 0.00038\n","Epoch 2, Step 1001, train_loss: 0.00028, val_loss: 0.00047\n","Epoch 2, Step 1101, train_loss: 0.00006, val_loss: 0.00042\n","Epoch 2, Step 1201, train_loss: 0.00048, val_loss: 0.00050\n","Epoch 2, Step 1301, train_loss: 0.00024, val_loss: 0.00040\n","Epoch 2, Step 1401, train_loss: 0.00010, val_loss: 0.00037\n","Epoch 3, Step 101, train_loss: 0.00053, val_loss: 0.00046\n","Epoch 3, Step 201, train_loss: 0.00038, val_loss: 0.00048\n","Epoch 3, Step 301, train_loss: 0.00031, val_loss: 0.00044\n","Epoch 3, Step 401, train_loss: 0.00135, val_loss: 0.00052\n","Epoch 3, Step 501, train_loss: 0.00090, val_loss: 0.00047\n","Epoch 3, Step 601, train_loss: 0.00098, val_loss: 0.00044\n","Epoch 3, Step 701, train_loss: 0.00038, val_loss: 0.00036\n","Epoch 3, Step 801, train_loss: 0.00128, val_loss: 0.00040\n","Epoch 3, Step 901, train_loss: 0.00050, val_loss: 0.00039\n","Epoch 3, Step 1001, train_loss: 0.00046, val_loss: 0.00042\n","Epoch 3, Step 1101, train_loss: 0.00027, val_loss: 0.00048\n","Epoch 3, Step 1201, train_loss: 0.00042, val_loss: 0.00043\n","Epoch 3, Step 1301, train_loss: 0.00025, val_loss: 0.00049\n","Epoch 3, Step 1401, train_loss: 0.00048, val_loss: 0.00044\n","Epoch 4, Step 101, train_loss: 0.00017, val_loss: 0.00037\n","Epoch 4, Step 201, train_loss: 0.00037, val_loss: 0.00033\n","Epoch 4, Step 301, train_loss: 0.00022, val_loss: 0.00034\n","Epoch 4, Step 401, train_loss: 0.00024, val_loss: 0.00038\n","Epoch 4, Step 501, train_loss: 0.00015, val_loss: 0.00035\n","Epoch 4, Step 601, train_loss: 0.00012, val_loss: 0.00031\n","Epoch 4, Step 701, train_loss: 0.00014, val_loss: 0.00031\n","Epoch 4, Step 801, train_loss: 0.00015, val_loss: 0.00031\n","Epoch 4, Step 901, train_loss: 0.00036, val_loss: 0.00031\n","Epoch 4, Step 1001, train_loss: 0.00019, val_loss: 0.00032\n","Epoch 4, Step 1101, train_loss: 0.00123, val_loss: 0.00037\n","Epoch 4, Step 1201, train_loss: 0.00009, val_loss: 0.00028\n","Model Inproved: 0.0003038512718292551 ----> 0.0002767173173527251\n","Epoch 4, Step 1301, train_loss: 0.00013, val_loss: 0.00028\n","Epoch 4, Step 1401, train_loss: 0.00070, val_loss: 0.00037\n","Epoch 5, Step 101, train_loss: 0.00013, val_loss: 0.00030\n","Epoch 5, Step 201, train_loss: 0.00008, val_loss: 0.00028\n","Epoch 5, Step 301, train_loss: 0.00011, val_loss: 0.00028\n","Epoch 5, Step 401, train_loss: 0.00008, val_loss: 0.00026\n","Model Inproved: 0.0002767173173527251 ----> 0.00026057106672933644\n","Epoch 5, Step 501, train_loss: 0.00012, val_loss: 0.00025\n","Model Inproved: 0.00026057106672933644 ----> 0.0002541031527569054\n","Epoch 5, Step 601, train_loss: 0.00007, val_loss: 0.00024\n","Model Inproved: 0.0002541031527569054 ----> 0.00024476184723302177\n","Epoch 5, Step 701, train_loss: 0.00008, val_loss: 0.00024\n","Model Inproved: 0.00024476184723302177 ----> 0.0002420281782453025\n","Epoch 5, Step 801, train_loss: 0.00010, val_loss: 0.00025\n","Epoch 5, Step 901, train_loss: 0.00004, val_loss: 0.00025\n","Epoch 5, Step 1001, train_loss: 0.00004, val_loss: 0.00024\n","Model Inproved: 0.0002420281782453025 ----> 0.00023569278365267128\n","Epoch 5, Step 1101, train_loss: 0.00006, val_loss: 0.00024\n","Epoch 5, Step 1201, train_loss: 0.00006, val_loss: 0.00024\n","Epoch 5, Step 1301, train_loss: 0.00006, val_loss: 0.00023\n","Model Inproved: 0.00023569278365267128 ----> 0.00023495163921575675\n","Epoch 5, Step 1401, train_loss: 0.00008, val_loss: 0.00023\n","Model Inproved: 0.00023495163921575675 ----> 0.00023461456162102848\n","Epoch 6, Step 101, train_loss: 0.00002, val_loss: 0.00023\n","Model Inproved: 0.00023461456162102848 ----> 0.000233715818883077\n","Epoch 6, Step 201, train_loss: 0.00009, val_loss: 0.00023\n","Model Inproved: 0.000233715818883077 ----> 0.00022863224048224253\n","Epoch 6, Step 301, train_loss: 0.00003, val_loss: 0.00023\n","Model Inproved: 0.00022863224048224253 ----> 0.00022773588980270796\n","Epoch 6, Step 401, train_loss: 0.00003, val_loss: 0.00023\n","Epoch 6, Step 501, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 6, Step 601, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 6, Step 701, train_loss: 0.00003, val_loss: 0.00023\n","Model Inproved: 0.00022773588980270796 ----> 0.00022590428049205823\n","Epoch 6, Step 801, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 6, Step 901, train_loss: 0.00006, val_loss: 0.00023\n","Epoch 6, Step 1001, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 6, Step 1101, train_loss: 0.00005, val_loss: 0.00023\n","Epoch 6, Step 1201, train_loss: 0.00006, val_loss: 0.00023\n","Epoch 6, Step 1301, train_loss: 0.00002, val_loss: 0.00023\n","Epoch 6, Step 1401, train_loss: 0.00005, val_loss: 0.00023\n","elasped time:  5.03e+03\n","accuracy: 0.7140959213498074\n","21500 / 30108\n","[0.00021455306739106753, 0.00018674067664881306, 0.0002586863836334605, 0.00022590428049205823]\n","Mean: 0.00022147110204134984\n","*** FOLD 5 / 5***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 101, train_loss: 0.00578, val_loss: 0.00770\n","Model Inproved: inf ----> 0.007702389064838481\n","Epoch 1, Step 201, train_loss: 0.00266, val_loss: 0.00203\n","Model Inproved: 0.007702389064838481 ----> 0.002027705932656924\n","Epoch 1, Step 301, train_loss: 0.00065, val_loss: 0.00115\n","Model Inproved: 0.002027705932656924 ----> 0.0011518586214268425\n","Epoch 1, Step 401, train_loss: 0.00090, val_loss: 0.00081\n","Model Inproved: 0.0011518586214268425 ----> 0.0008139503291008866\n","Epoch 1, Step 501, train_loss: 0.00065, val_loss: 0.00061\n","Model Inproved: 0.0008139503291008866 ----> 0.0006120846104489012\n","Epoch 1, Step 601, train_loss: 0.00046, val_loss: 0.00053\n","Model Inproved: 0.0006120846104489012 ----> 0.0005273945401956493\n","Epoch 1, Step 701, train_loss: 0.00022, val_loss: 0.00047\n","Model Inproved: 0.0005273945401956493 ----> 0.0004731725924917098\n","Epoch 1, Step 801, train_loss: 0.00031, val_loss: 0.00039\n","Model Inproved: 0.0004731725924917098 ----> 0.0003917792720326438\n","Epoch 1, Step 901, train_loss: 0.00029, val_loss: 0.00037\n","Model Inproved: 0.0003917792720326438 ----> 0.0003704615419009875\n","Epoch 1, Step 1001, train_loss: 0.00029, val_loss: 0.00035\n","Model Inproved: 0.0003704615419009875 ----> 0.00034760623432647286\n","Epoch 1, Step 1101, train_loss: 0.00020, val_loss: 0.00029\n","Model Inproved: 0.00034760623432647286 ----> 0.00029091416383899876\n","Epoch 1, Step 1201, train_loss: 0.00014, val_loss: 0.00030\n","Epoch 1, Step 1301, train_loss: 0.00017, val_loss: 0.00035\n","Epoch 1, Step 1401, train_loss: 0.00027, val_loss: 0.00027\n","Model Inproved: 0.00029091416383899876 ----> 0.0002713035642143895\n","Epoch 2, Step 101, train_loss: 0.00037, val_loss: 0.00030\n","Epoch 2, Step 201, train_loss: 0.00044, val_loss: 0.00034\n","Epoch 2, Step 301, train_loss: 0.00026, val_loss: 0.00035\n","Epoch 2, Step 401, train_loss: 0.00024, val_loss: 0.00033\n","Epoch 2, Step 501, train_loss: 0.00021, val_loss: 0.00035\n","Epoch 2, Step 601, train_loss: 0.00040, val_loss: 0.00034\n","Epoch 2, Step 701, train_loss: 0.00020, val_loss: 0.00038\n","Epoch 2, Step 801, train_loss: 0.00046, val_loss: 0.00039\n","Epoch 2, Step 901, train_loss: 0.00037, val_loss: 0.00045\n","Epoch 2, Step 1001, train_loss: 0.00030, val_loss: 0.00035\n","Epoch 2, Step 1101, train_loss: 0.00019, val_loss: 0.00038\n","Epoch 2, Step 1201, train_loss: 0.00019, val_loss: 0.00038\n","Epoch 2, Step 1301, train_loss: 0.00026, val_loss: 0.00042\n","Epoch 2, Step 1401, train_loss: 0.00054, val_loss: 0.00043\n","Epoch 3, Step 101, train_loss: 0.00139, val_loss: 0.00044\n","Epoch 3, Step 201, train_loss: 0.00017, val_loss: 0.00048\n","Epoch 3, Step 301, train_loss: 0.00042, val_loss: 0.00040\n","Epoch 3, Step 401, train_loss: 0.00034, val_loss: 0.00038\n","Epoch 3, Step 501, train_loss: 0.00017, val_loss: 0.00041\n","Epoch 3, Step 601, train_loss: 0.00043, val_loss: 0.00034\n","Epoch 3, Step 701, train_loss: 0.00020, val_loss: 0.00030\n","Epoch 3, Step 801, train_loss: 0.00051, val_loss: 0.00034\n","Epoch 3, Step 901, train_loss: 0.00012, val_loss: 0.00032\n","Epoch 3, Step 1001, train_loss: 0.00035, val_loss: 0.00045\n","Epoch 3, Step 1101, train_loss: 0.00062, val_loss: 0.00033\n","Epoch 3, Step 1201, train_loss: 0.00040, val_loss: 0.00035\n","Epoch 3, Step 1301, train_loss: 0.00021, val_loss: 0.00034\n","Epoch 3, Step 1401, train_loss: 0.00027, val_loss: 0.00030\n","Epoch 4, Step 101, train_loss: 0.00018, val_loss: 0.00033\n","Epoch 4, Step 201, train_loss: 0.00026, val_loss: 0.00029\n","Epoch 4, Step 301, train_loss: 0.00012, val_loss: 0.00030\n","Epoch 4, Step 401, train_loss: 0.00014, val_loss: 0.00027\n","Model Inproved: 0.0002713035642143895 ----> 0.00026502752138196856\n","Epoch 4, Step 501, train_loss: 0.00011, val_loss: 0.00027\n","Epoch 4, Step 601, train_loss: 0.00020, val_loss: 0.00030\n","Epoch 4, Step 701, train_loss: 0.00031, val_loss: 0.00030\n","Epoch 4, Step 801, train_loss: 0.00014, val_loss: 0.00026\n","Model Inproved: 0.00026502752138196856 ----> 0.0002618142662691168\n","Epoch 4, Step 901, train_loss: 0.00022, val_loss: 0.00030\n","Epoch 4, Step 1001, train_loss: 0.00017, val_loss: 0.00027\n","Epoch 4, Step 1101, train_loss: 0.00033, val_loss: 0.00028\n","Epoch 4, Step 1201, train_loss: 0.00009, val_loss: 0.00027\n","Epoch 4, Step 1301, train_loss: 0.00029, val_loss: 0.00031\n","Epoch 4, Step 1401, train_loss: 0.00013, val_loss: 0.00024\n","Model Inproved: 0.0002618142662691168 ----> 0.00023734932995343633\n","Epoch 5, Step 101, train_loss: 0.00007, val_loss: 0.00022\n","Model Inproved: 0.00023734932995343633 ----> 0.00022056882665383862\n","Epoch 5, Step 201, train_loss: 0.00009, val_loss: 0.00023\n","Epoch 5, Step 301, train_loss: 0.00035, val_loss: 0.00021\n","Model Inproved: 0.00022056882665383862 ----> 0.00020552091703822655\n","Epoch 5, Step 401, train_loss: 0.00008, val_loss: 0.00022\n","Epoch 5, Step 501, train_loss: 0.00005, val_loss: 0.00021\n","Epoch 5, Step 601, train_loss: 0.00043, val_loss: 0.00021\n","Epoch 5, Step 701, train_loss: 0.00005, val_loss: 0.00020\n","Model Inproved: 0.00020552091703822655 ----> 0.00020204823605835383\n","Epoch 5, Step 801, train_loss: 0.00011, val_loss: 0.00020\n","Epoch 5, Step 901, train_loss: 0.00006, val_loss: 0.00022\n","Epoch 5, Step 1001, train_loss: 0.00009, val_loss: 0.00021\n","Epoch 5, Step 1101, train_loss: 0.00006, val_loss: 0.00020\n","Model Inproved: 0.00020204823605835383 ----> 0.0001994933240949065\n","Epoch 5, Step 1201, train_loss: 0.00013, val_loss: 0.00019\n","Model Inproved: 0.0001994933240949065 ----> 0.0001893869422869185\n","Epoch 5, Step 1301, train_loss: 0.00003, val_loss: 0.00020\n","Epoch 5, Step 1401, train_loss: 0.00003, val_loss: 0.00019\n","Epoch 6, Step 101, train_loss: 0.00002, val_loss: 0.00019\n","Model Inproved: 0.0001893869422869185 ----> 0.00018890855178581295\n","Epoch 6, Step 201, train_loss: 0.00003, val_loss: 0.00019\n","Model Inproved: 0.00018890855178581295 ----> 0.0001877515827028163\n","Epoch 6, Step 301, train_loss: 0.00003, val_loss: 0.00019\n","Epoch 6, Step 401, train_loss: 0.00008, val_loss: 0.00019\n","Model Inproved: 0.0001877515827028163 ----> 0.00018713040551162008\n","Epoch 6, Step 501, train_loss: 0.00002, val_loss: 0.00018\n","Model Inproved: 0.00018713040551162008 ----> 0.00018465725557069646\n","Epoch 6, Step 601, train_loss: 0.00004, val_loss: 0.00018\n","Model Inproved: 0.00018465725557069646 ----> 0.00018439200636288628\n","Epoch 6, Step 701, train_loss: 0.00006, val_loss: 0.00018\n","Model Inproved: 0.00018439200636288628 ----> 0.00018336685039237614\n","Epoch 6, Step 801, train_loss: 0.00002, val_loss: 0.00018\n","Epoch 6, Step 901, train_loss: 0.00002, val_loss: 0.00018\n","Epoch 6, Step 1001, train_loss: 0.00003, val_loss: 0.00018\n","Epoch 6, Step 1101, train_loss: 0.00003, val_loss: 0.00018\n","Epoch 6, Step 1201, train_loss: 0.00005, val_loss: 0.00018\n","Epoch 6, Step 1301, train_loss: 0.00003, val_loss: 0.00018\n","Epoch 6, Step 1401, train_loss: 0.00003, val_loss: 0.00018\n","elasped time:  5.06e+03\n","accuracy: 0.7138302112395377\n","21492 / 30108\n","[0.00021455306739106753, 0.00018674067664881306, 0.0002586863836334605, 0.00022590428049205823, 0.00018336685039237614]\n","Mean: 0.0002138502517115551\n"]}],"source":["# ----------------------------------------------\n","# Main Loop\n","# ----------------------------------------------\n","if TRAIN:\n","    val_scores = []\n","    # val: less, more別々にdf作成 -> スコアを予測し、「more > less」である率を計測する。\n","    less_df_src = val_data[['less_toxic']].rename({'less_toxic': 'comment_text'}, axis='columns')\n","    more_df_src = val_data[['more_toxic']].rename({'more_toxic': 'comment_text'}, axis='columns')\n","    less_dataset = TweetJigsawDataset(less_df_src, inference_only=True)\n","    more_dataset = TweetJigsawDataset(more_df_src, inference_only=True)\n","    \n","    for fold in range(FOLDS): \n","        print(f\"*** FOLD {fold+1} / {FOLDS}***\")\n","\n","        save_path = f\"/content/model/model_{fold+1}.pth\"\n","\n","        train_set = TweetJigsawDataset(train[train['kfold'] != fold])\n","        valid_set = TweetJigsawDataset(train[train['kfold'] == fold])\n","\n","        train_loader = DataLoader(train_set,\n","                                batch_size=BATCH_SIZE,\n","                                shuffle=True,\n","                                drop_last=True,\n","                                num_workers=2)\n","        valid_loader = DataLoader(valid_set,\n","                                batch_size=BATCH_SIZE,\n","                                shuffle=False,\n","                                drop_last=False,\n","                                num_workers=2)\n","\n","        model = TweetJigsawModel().to(DEVICE)\n","        optimizer = AdamW(model.parameters(), lr=LEANING_RATE)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_training_steps=NUM_EPOCHS*len(train_loader),\n","            num_warmup_steps=50\n","        )\n","\n","        val_scores.append(\n","            train_fn(model, save_path, train_loader, valid_loader, optimizer, scheduler=scheduler)\n","        )\n","        calc_val_in_step(model, less_dataset, more_dataset)\n","        del model\n","        torch.cuda.empty_cache()\n","\n","        print(val_scores)\n","        print(\"Mean:\", np.array(val_scores).mean())"]},{"cell_type":"markdown","metadata":{"id":"QRp8W2zmMnit"},"source":["# Predict or Load Valid data"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1644186105595,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"PmvFLO0EMxDR","outputId":"be4a9349-2961-46c5-8732-b66453d3c294"},"outputs":[{"name":"stdout","output_type":"stream","text":["['/content/model/model_1.pth', '/content/model/model_2.pth', '/content/model/model_3.pth', '/content/model/model_4.pth', '/content/model/model_5.pth']\n"]}],"source":["model_path = UPLOAD_DIR\n","models = sorted([str(i) for i in list(model_path.iterdir())])[1:]\n","print(models)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1644186105596,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"pOQf_fo_L_sk"},"outputs":[],"source":["# val: less, more別々にdf作成 -> スコアを予測し、「more > less」である率を計測する。\n","val_less = val_data[['less_toxic']].rename({'less_toxic': 'comment_text'}, axis='columns')\n","val_more = val_data[['more_toxic']].rename({'more_toxic': 'comment_text'}, axis='columns')"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1644186105596,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"M0smOm3PkSwK"},"outputs":[],"source":["def calc_val(model, model_path, less_dataset, more_dataset):\n","    less_pred = np.zeros((FOLDS, len(less_dataset), 6))\n","    more_pred = np.zeros((FOLDS, len(more_dataset), 6))\n","\n","    less_loader = DataLoader(less_dataset, batch_size=BATCH_SIZE,\n","                             drop_last=False, shuffle=False, num_workers=2)\n","    more_loader = DataLoader(more_dataset, batch_size=BATCH_SIZE,\n","                             drop_last=False, shuffle=False, num_workers=2)\n","\n","    for i, model_ in enumerate(model_path):\n","        print(f\"model-{i}: start\")\n","\n","        model.to(DEVICE)\n","        model.load_state_dict(torch.load(model_))\n","\n","        less_pred[i, :] = predict(model, less_loader)\n","        more_pred[i, :] = predict(model, more_loader)\n","        print(f\"model-{i}: complete\")\n","\n","    less_mean = less_pred.mean(axis=0)\n","    #less_mean = scaler_.transform(less_mean)\n","    more_mean = more_pred.mean(axis=0)\n","    #more_mean = scaler_.transform(more_mean)\n","\n","    val_scores = pd.DataFrame({'worker': val_data['worker'].head(len(less_dataset)),\n","                               'less_score': less_mean.sum(axis=1),\n","                               'more_score': more_mean.sum(axis=1),})\n","    val_scores['score_diff'] = val_scores['more_score'] - val_scores['less_score']\n","    val_scores['correct_ans'] = val_scores['score_diff'] > 0\n","\n","    acc = val_scores['correct_ans'].sum() / len(val_scores)\n","\n","    print(f\"accuracy: {acc}\")\n","    print(f\"{val_scores['correct_ans'].sum()} / {len(val_scores)}\")\n","    return less_mean, more_mean, val_scores"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":711604,"status":"ok","timestamp":1644193516056,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"Wx9W2oAsPgHs","outputId":"02a612ff-fdad-49cb-b62c-a84948c45e2c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model-0: start\n","model-0: complete\n","model-1: start\n","model-1: complete\n","model-2: start\n","model-2: complete\n","model-3: start\n","model-3: complete\n","model-4: start\n","model-4: complete\n","accuracy: 0.7141955626411585\n","21503 / 30108\n"]}],"source":["if RUN_VALID:\n","  model = TweetJigsawModel()\n","  less_dataset = TweetJigsawDataset(val_less, inference_only=True)\n","  more_dataset = TweetJigsawDataset(val_more, inference_only=True)\n","\n","  less_, more_, scores = calc_val(model, models, less_dataset, more_dataset)\n","  pd.DataFrame(less_).to_csv(OUT_DIR/'less_df.csv', index=False)\n","  pd.DataFrame(more_).to_csv(OUT_DIR/'more_df.csv', index=False)\n","  scores.to_csv(OUT_DIR/'out_score.csv', index=False)\n","  scores.head()\n","\n","else:\n","  less_df = pd.read_csv(OUT_DIR/'less_df.csv')\n","  more_df = pd.read_csv(OUT_DIR/'more_df.csv')"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1644186828680,"user":{"displayName":"堂込一智","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0KUBIwJ38GUlukN0OqZB0q5CTq1FUqQQ45Eml7w=s64","userId":"12219727497971505625"},"user_tz":-540},"id":"4EP9u6HEHhrl"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMEpdzJFlZ0BQXD4VWPoRCC","background_execution":"on","collapsed_sections":[],"mount_file_id":"1XxnOf3zVf8mU9d1XyaXRLRwEn7F1O1Jf","name":"calpis-012.ipynb","provenance":[{"file_id":"1D21nAavRAGrSCn5EOJ_82M8Ek7cETO4G","timestamp":1643437303050},{"file_id":"1A-_5tr-NwF4RUNsqBS_fsZ3ZfHtXRxPg","timestamp":1643433038902},{"file_id":"1qU0epg8LcfuR6egJhl4BVSp-p7heY201","timestamp":1643424460456},{"file_id":"12Y6FjvQMqz0v0c20GqwrsJIq6l9X61K1","timestamp":1643419024540},{"file_id":"1E7OC1O__qj14BzVZHDsIYgqoOEh6PfDP","timestamp":1643375050643},{"file_id":"1OTfi82QAmeROtNWaS1ykG8ROVUvG9TDK","timestamp":1643155772647},{"file_id":"1teetF6U9uIL5kT0wNc0fH4AGRjX8Icux","timestamp":1643098853642},{"file_id":"1fBWjLs_VWGdtCm8I7NOA9BNixWqigUiK","timestamp":1638329371432},{"file_id":"19kyMmv8MoUznXvQ7pEVv7DIpVhGfroxO","timestamp":1638148434790},{"file_id":"1m2opANSAu0f6JSVhVAGXiULprzaG2BA5","timestamp":1638071812320},{"file_id":"1WL8hIv_RgQrxzWiQz_YLbalnY7yF5x4d","timestamp":1637753999122},{"file_id":"1gJFOrI0qy1Q3ilk5t6MWn68czi81mJWX","timestamp":1637557926622},{"file_id":"1AGKdYWEJiSyvxeY-Teo0i-hm7UI8ucSV","timestamp":1637502066835}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"003298ae717145648346ab6ecc9aacb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e66a8671e3d24f3a940220568bea2a7e","IPY_MODEL_1e96954d891e4030a307e815d09e356f","IPY_MODEL_0631c2a5c9b44c41ac0f593c9e7097ef"],"layout":"IPY_MODEL_3e0d62ac215b4e00ab3ae16ae7334831"}},"00e8ef3b865e49a68a11833ee8ca59af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05b8528bf38044038e00b8284c172ef5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d28eb491b36c4d929112987c532adbfd","IPY_MODEL_c7e585f5a4dd4fb6917206112fad7ce8","IPY_MODEL_cdbdec203b1b4cbfb598c8f07a317e77"],"layout":"IPY_MODEL_301c04bc370d4e6895e4f8772a10f2ae"}},"0631c2a5c9b44c41ac0f593c9e7097ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4868893c74224417ba0f1111f6859926","placeholder":"​","style":"IPY_MODEL_562f778204b54fed8230d98757fc1f97","value":" 4.83M/4.83M [00:00&lt;00:00, 9.10MB/s]"}},"0acdccfb338541e48756ad6f553ec646":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c68e8aa30764906a56816e0ee495d9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e0fc0e3236747a59d0b8986ab0f7b15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f1ae8ce8dc24539879aca98b44ff0ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6096fc85ac64016bb65e85f87a446cf","IPY_MODEL_679662ac6cd4433fa9fcc5690650ec1b","IPY_MODEL_a44e6e3deb724ae2bd2a9a4e6357026c"],"layout":"IPY_MODEL_5bf6283b390d40b2b07aaf8901d46aa7"}},"115845e94c6242699d817e6e2289c6f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ab175e4a17e4b5a819da0bbaee05f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e96954d891e4030a307e815d09e356f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66ae8795646a4298bcd96a0c033cc6ae","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c68e8aa30764906a56816e0ee495d9b","value":5069051}},"27fc894e924a404092a805ed5e70bb69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9ea8d23fcd4d00a6a045130c56bd23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c26b70c9da4400eb5c8c5732d8fd5c7","placeholder":"​","style":"IPY_MODEL_481a1ba11dd9422cb67f0ccc44686f95","value":" 635/635 [00:00&lt;00:00, 21.6kB/s]"}},"2e053ffa6fee4f66ac1218f6d9441df2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"301c04bc370d4e6895e4f8772a10f2ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30aedff7992b42628d45218396deb47b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35c0a12bb1d34d67acc2bdabf75e9996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e0d62ac215b4e00ab3ae16ae7334831":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"481a1ba11dd9422cb67f0ccc44686f95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4868893c74224417ba0f1111f6859926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5163e57a964b4af6801d08aec2db076d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e053ffa6fee4f66ac1218f6d9441df2","placeholder":"​","style":"IPY_MODEL_dd6fb1c0dd0149279318bfe8a6684e5b","value":"Downloading: 100%"}},"562f778204b54fed8230d98757fc1f97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5804b0854c294950a3a376b9425f6d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bf6283b390d40b2b07aaf8901d46aa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6567c378e87f405c82dc74fe0324a33b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66ae8795646a4298bcd96a0c033cc6ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"679662ac6cd4433fa9fcc5690650ec1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_115845e94c6242699d817e6e2289c6f1","max":1112265417,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6567c378e87f405c82dc74fe0324a33b","value":1112265417}},"7b511ef31fb04c18b25baeddca6ba042":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84986eac783a4de799fde7f902228e2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c26b70c9da4400eb5c8c5732d8fd5c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca50feee5a54faebee45f84c7eca62d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5e822ca47894a8689fb3d9d38a10537","IPY_MODEL_ab7acbc61b1e42239b37b8d7c3c8542d","IPY_MODEL_2b9ea8d23fcd4d00a6a045130c56bd23"],"layout":"IPY_MODEL_f97d26a9c9b1442388fa8f082fb37685"}},"9a1de4144e834f699de72979403124a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a44e6e3deb724ae2bd2a9a4e6357026c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27fc894e924a404092a805ed5e70bb69","placeholder":"​","style":"IPY_MODEL_30aedff7992b42628d45218396deb47b","value":" 1.04G/1.04G [00:21&lt;00:00, 56.1MB/s]"}},"a485ce636c4649cfa8c381b2654d84be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab7acbc61b1e42239b37b8d7c3c8542d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b511ef31fb04c18b25baeddca6ba042","max":635,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c36bfcaba0a7491083b3a6f40d259658","value":635}},"b5e822ca47894a8689fb3d9d38a10537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf056ae0e1014506b54bc628bf12a1d5","placeholder":"​","style":"IPY_MODEL_c949e0d44b1e45838dd85a56e1c4abe8","value":"Downloading: 100%"}},"bdc823b669714eef9becd0bfc50e8cb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be47369ceb21478cbc934c6ca7ea0db2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36bfcaba0a7491083b3a6f40d259658":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7e585f5a4dd4fb6917206112fad7ce8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84986eac783a4de799fde7f902228e2b","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35c0a12bb1d34d67acc2bdabf75e9996","value":150}},"c949e0d44b1e45838dd85a56e1c4abe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdbdec203b1b4cbfb598c8f07a317e77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a485ce636c4649cfa8c381b2654d84be","placeholder":"​","style":"IPY_MODEL_dc11ae6f211941feb4f1729456b894c4","value":" 150/150 [00:00&lt;00:00, 4.43kB/s]"}},"cf056ae0e1014506b54bc628bf12a1d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d28eb491b36c4d929112987c532adbfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be47369ceb21478cbc934c6ca7ea0db2","placeholder":"​","style":"IPY_MODEL_0acdccfb338541e48756ad6f553ec646","value":"Downloading: 100%"}},"d3490f81ad924eeb9cadb862268d8f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5163e57a964b4af6801d08aec2db076d","IPY_MODEL_e2883701461148c3bda2c6cba01ff647","IPY_MODEL_e9e7d6d843454c6db4fd060a5756778a"],"layout":"IPY_MODEL_9a1de4144e834f699de72979403124a2"}},"d6096fc85ac64016bb65e85f87a446cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00e8ef3b865e49a68a11833ee8ca59af","placeholder":"​","style":"IPY_MODEL_e9f3ea5643b04654a02a1ba01e991a1e","value":"Downloading: 100%"}},"dc11ae6f211941feb4f1729456b894c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd6fb1c0dd0149279318bfe8a6684e5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df59c3f7e68c414993eb151d3c8f0611":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2883701461148c3bda2c6cba01ff647":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df59c3f7e68c414993eb151d3c8f0611","max":211,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5804b0854c294950a3a376b9425f6d8e","value":211}},"e66a8671e3d24f3a940220568bea2a7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff0e3131fa25497e94342f0afe64a819","placeholder":"​","style":"IPY_MODEL_1ab175e4a17e4b5a819da0bbaee05f52","value":"Downloading: 100%"}},"e9e7d6d843454c6db4fd060a5756778a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0fc0e3236747a59d0b8986ab0f7b15","placeholder":"​","style":"IPY_MODEL_bdc823b669714eef9becd0bfc50e8cb0","value":" 211/211 [00:00&lt;00:00, 5.99kB/s]"}},"e9f3ea5643b04654a02a1ba01e991a1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f97d26a9c9b1442388fa8f082fb37685":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0e3131fa25497e94342f0afe64a819":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
